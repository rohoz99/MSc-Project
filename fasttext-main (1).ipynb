{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport pandas as pd\nimport numpy\nimport time\nfrom gensim.models.fasttext import FastText\nfrom gensim.models.doc2vec import TaggedDocument, Doc2Vec\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn import neighbors\nimport pickle\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score\nfrom sklearn import utils\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nimport nltk\nfrom tqdm import tqdm\ntqdm.pandas(desc=\"progress-bar\")\n\n\nfrom nltk.corpus import stopwords\nimport multiprocessing\n\ncores = multiprocessing.cpu_count()\nFastTextModel = \"fasttext_model.sav\"\n\nallContent = \"\"\npath1 = \"../input/ps-dataset/powershell_benign_dataset/\"\npath2 = \"../input/ps-dataset/malicious_pure\"\n#path3 = r\"D:\\Test Scripts\"\nlabels = []\ntext = []\ntestText = []\n#new_str = re.sub('[^a-zA-Z0-9\\n\\.]', ' ', string)\nfName= []\nnewText = []\nregex = r':\\s*\\n+'\nvectorizer = CountVectorizer(stop_words='english', max_features=5000)\n\ndef test_bowser(path):\n        with open(path, encoding='utf-8') as f:\n            t_content = f.read()\n            t_content = t_content.lower()\n            t_content = t_content.replace(\"(\", \"\")\n            t_content = t_content.replace(\")\", \"\")\n            t_content = t_content.replace(\"[\", \"\")\n            t_content = t_content.replace(\"]\", \"\")\n            t_content = t_content.replace(\"$\", \"\")\n            t_content = t_content.replace(\"-\", \"\")\n            t_content = t_content.replace(\"=\", \"\")\n            t_content = t_content.replace(\"\", \"\")\n            t_content = t_content.replace(\"{\", \"\")\n            t_content = t_content.replace(\"}\", \"\")\n            t_content = t_content.replace(\".\", \"\")\n            t_content = t_content.replace(\"_\", \"\")\n            t_content = t_content.replace(\"|\", \"\")\n            t_content = t_content.replace(\":\", \"\")\n            t_content = t_content.replace(\"|\", \"\")\n            t_content = t_content.replace(\"/\", \"\")\n            t_content = t_content.replace(\"@\", \"\")\n            t_content = t_content.replace(\"?\", \"\")\n            t_content = t_content.replace(\",\", \"\")\n            t_content = t_content.replace(\">\", \"\")\n            t_content = t_content.replace(\"<\", \"\")\n            t_content = t_content.replace(\";\", \"\")\n            t_content = t_content.replace(\"\\\\\", \"\")\n            t_content = t_content.replace(\"+\", \"\")\n            t_content = t_content.replace(\"\\\"\",\"\")\n            t_content = t_content.replace(\"\\'\",\"\")\n            t_content = t_content.replace(\"`\", \"\")\n            t_content = t_content.replace(\"*\", \"\")\n            t_content = \" \".join(t_content.split())\n            newText.append(t_content)\n            return t_content\n\ndef bowser(path, label):\n    for filename in os.listdir(path):\n        labelName = \"__label__\" + label\n        labels.append(labelName)\n        filename = os.path.join(path, filename)\n        with open(filename, encoding='utf-8') as f:\n                    content = f.read()\n                    content = content.lower()\n                    content = content.replace(\"(\", \"\")\n                    content = content.replace(\")\", \"\")\n                    content = content.replace(\"[\", \"\")\n                    content = content.replace(\"]\", \"\")\n                    content = content.replace(\"$\", \"\")\n                    content = content.replace(\"-\", \"\")\n                    content = content.replace(\"!\",\"\")\n                    content = content.replace(\"=\", \"\")\n                    content = content.replace(\"\", \"\")\n                    content = content.replace(\"{\", \"\")\n                    content = content.replace(\"}\", \"\")\n                    content = content.replace(\".\", \"\")\n                    content = content.replace(\"_\", \"\")\n                    content = content.replace(\"|\", \"\")\n                    content = content.replace(\":\", \"\")\n                    content = content.replace(\"|\", \"\")\n                    content = content.replace(\"/\", \"\")\n                    content = content.replace(\"@\", \"\")\n                    content = content.replace(\"?\", \"\")\n                    content = content.replace(\",\", \"\")\n                    content = content.replace(\">\", \"\")\n                    content = content.replace(\"<\", \"\")\n                    content = content.replace(\";\", \"\")\n                    content = content.replace(\"\\\\\", \"\")\n                    content = content.replace(\"+\", \"\")\n                    content = content.replace(\"\\\"\", \"\")\n                    content = content.replace(\"\\'\", \"\")\n                    content = content.replace(\"`\", \"\")\n                    content = content.replace(\"*\", \"\")\n                    content = \" \".join(content.split())\n                    testText.append(content)\n\n\n#test_bowser(path3)\nbowser(path1,\"Benign\")\nbowser(path2,\"Malicious\")\n#print(testText[6])\nnumFiles = len(testText)\n#res = [re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", ele) for ele in testText]\n#print(res[1] + \"\\n\")\n\ndf = pd.DataFrame(testText, columns=[\"Powershell Code\"])\ndf['Labels'] = labels\n#df.to_csv('tester.csv')\nprint(df)\n\ntrain, test = train_test_split(df, test_size=0.3, random_state=42)\ntrain_size = len(train['Powershell Code'])\ntrain.reset_index()\ntrain.reindex(index=range(0,5962))\nprint(train)\n\ndef tokenize_text(text):\n    tokens = []\n    for sent in nltk.sent_tokenize(text):\n        for word in nltk.word_tokenize(sent):\n            if len(word) < 2:\n                continue\n            tokens.append(word.lower())\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2022-09-09T06:28:59.671986Z","iopub.execute_input":"2022-09-09T06:28:59.672494Z","iopub.status.idle":"2022-09-09T06:30:00.766844Z","shell.execute_reply.started":"2022-09-09T06:28:59.672363Z","shell.execute_reply":"2022-09-09T06:30:00.765521Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"i =0\noutput = \"\"\nwhile (i<5961):\n    output = output + (train['Labels'].iloc[i]+\" \"+train['Powershell Code'].iloc[i]+\".\\n\")\n    i = i+1\n\nwith open('powershell.txt', 'w') as f:\n    f.write(output)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T06:30:00.769349Z","iopub.execute_input":"2022-09-09T06:30:00.770154Z","iopub.status.idle":"2022-09-09T06:30:01.235011Z","shell.execute_reply.started":"2022-09-09T06:30:00.770104Z","shell.execute_reply":"2022-09-09T06:30:01.233957Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import fasttext\nmodel = fasttext.train_supervised(input=\"./powershell.txt\")\nmodel.save_model(\"model_powershell.bin\")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-09T06:30:01.236731Z","iopub.execute_input":"2022-09-09T06:30:01.237386Z","iopub.status.idle":"2022-09-09T06:30:03.453768Z","shell.execute_reply.started":"2022-09-09T06:30:01.237345Z","shell.execute_reply":"2022-09-09T06:30:03.450808Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"i=0\nwhile (i<55):\n    print(\"\\n\")\n    input = test['Powershell Code'].iloc[i]\n    print(model.predict(input))\n    print(\"Correct Label:\"+ test['Labels'].iloc[i])\n    i=i+1","metadata":{"execution":{"iopub.status.busy":"2022-09-09T06:30:03.458271Z","iopub.execute_input":"2022-09-09T06:30:03.458856Z","iopub.status.idle":"2022-09-09T06:30:03.493359Z","shell.execute_reply.started":"2022-09-09T06:30:03.458806Z","shell.execute_reply":"2022-09-09T06:30:03.491992Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score, f1_score\n\ntest_data = list(test['Powershell Code'])\ntest_labels = list(test['Labels'])\n#print(model.predict(test_data)[0])\ny_pred = model.predict(test_data)\n\n#print(test_labels)\nprint(classification_report(test_labels,y_pred[0],digits=6))","metadata":{"execution":{"iopub.status.busy":"2022-09-09T06:30:03.495084Z","iopub.execute_input":"2022-09-09T06:30:03.497184Z","iopub.status.idle":"2022-09-09T06:30:04.071512Z","shell.execute_reply.started":"2022-09-09T06:30:03.497101Z","shell.execute_reply":"2022-09-09T06:30:04.069525Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"st = time.time()\nkk = test_bowser(\"../input/ps-dataset/malicious_pure/1010.ps1\")\nprint(model.predict(kk))\nend = time.time()\n\nprint(end-st)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T06:30:04.073401Z","iopub.execute_input":"2022-09-09T06:30:04.073916Z","iopub.status.idle":"2022-09-09T06:30:04.083332Z","shell.execute_reply.started":"2022-09-09T06:30:04.073878Z","shell.execute_reply":"2022-09-09T06:30:04.081870Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 2","metadata":{}},{"cell_type":"code","source":"dataset_2 = pd.read_csv('../input/ps-dataset-2/Dataset_2.csv')\np=0\nwhile p < 6804:\n    dataset_2['Labels'].iloc[p] = \"__label__\" + dataset_2['Labels'].iloc[p]\n    p= p+1\n\ntrain2, test2 = train_test_split(dataset_2, test_size=0.3, random_state=42)\n\ni =0\noutput = \"\"\nwhile (i<4763):\n    output = output + \"__label__\"+train2['Labels'].iloc[i] +\" \"+ (train2['Powershell Code'].iloc[i])+\".\\n\"\n    i = i+1\n    \n\nwith open('powershell_dataset2.txt', 'w') as f:\n    f.write(output)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-09T06:49:39.765132Z","iopub.execute_input":"2022-09-09T06:49:39.765528Z","iopub.status.idle":"2022-09-09T06:50:13.051165Z","shell.execute_reply.started":"2022-09-09T06:49:39.765495Z","shell.execute_reply":"2022-09-09T06:50:13.049905Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import fasttext\nmodel2 = fasttext.train_supervised(input=\"../input/ps-fasttext-dataset-2/powershell_dataset2 (5).txt\")\nmodel2.save_model(\"model2_powershell.bin\")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-09T06:51:58.800896Z","iopub.execute_input":"2022-09-09T06:51:58.801284Z","iopub.status.idle":"2022-09-09T06:52:00.312196Z","shell.execute_reply.started":"2022-09-09T06:51:58.801253Z","shell.execute_reply":"2022-09-09T06:52:00.310350Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score, f1_score\n\ntest_data2 = list(test2['Powershell Code'])\ntest_labels2 = list(test2['Labels'])\n#print(model.predict(test_data)[0])\ny_pred = model2.predict(test_data2)\n\n#print(test_labels)\nprint(classification_report(test_labels2,y_pred[0],digits=6))","metadata":{"execution":{"iopub.status.busy":"2022-09-09T06:52:04.220046Z","iopub.execute_input":"2022-09-09T06:52:04.220584Z","iopub.status.idle":"2022-09-09T06:52:04.436606Z","shell.execute_reply.started":"2022-09-09T06:52:04.220538Z","shell.execute_reply":"2022-09-09T06:52:04.435488Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#CROSS VAL DATASET2 ON MODEL 1\ny_pred = model.predict(test_data2)\n\n#print(test_labels)\nprint(classification_report(test_labels2,y_pred[0],digits=6))","metadata":{"execution":{"iopub.status.busy":"2022-09-09T06:52:20.974664Z","iopub.execute_input":"2022-09-09T06:52:20.975058Z","iopub.status.idle":"2022-09-09T06:52:21.183616Z","shell.execute_reply.started":"2022-09-09T06:52:20.975027Z","shell.execute_reply":"2022-09-09T06:52:21.182451Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#CROSS VAL DATASET1 ON MODEL 2\ny_pred = model2.predict(test_data)\n\n#print(test_labels)\nprint(classification_report(test_labels,y_pred[0],digits=6))\n\nplot_learning_curves(X_train2, Y_train2, X_test2, Y_test2, svclassifier2)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-09T06:52:24.418366Z","iopub.execute_input":"2022-09-09T06:52:24.418767Z","iopub.status.idle":"2022-09-09T06:52:24.873316Z","shell.execute_reply.started":"2022-09-09T06:52:24.418737Z","shell.execute_reply":"2022-09-09T06:52:24.871962Z"},"trusted":true},"execution_count":14,"outputs":[]}]}